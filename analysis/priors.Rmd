---
title: "Computing prior hyperparameters"
output:
  workflowr::wflow_html:
    toc: false
editor_options:
  chunk_output_type: console
---

### <i><b><span style="color:salmon">---Special considerations: this portion is highly parallelizable---</span></b></i>

```{r, echo = FALSE}
knitr::opts_chunk$set(autodep = TRUE, warning = FALSE, message = FALSE)
```

We are now just about ready to set up our MCMC. First, we need to determine the hyperparameters in the priors of our Gaussian mixture. These are all calculated in an empirical Bayesian manner -- that is, we can recycle information from the pairwise fits to inform our priors in the full-information mixture. This task can be split into 2 sub-tasks:

1. computing the prior hyperparameters for the cluster mixing weights

2. computing every other hyperparameter

The former is the most essential, as it helps us remove more candidate latent classes, ensuring that the number of clusters is fewer than the number of observations. **An important note**: this is the *only* step of CLIMB that requires some sort of human intervention, but it does need to happen. A threshold, called $\delta$ in the manuscript, determines how strict one is about including classes in the final model. $\delta\in\{0,1,\ldots,\binom{D}{2}\}$. We will get into selecting $\delta$ shortly.

To get the prior weights on each candidate latent class, use the function `get_prior_weights()`. This function defaults to the settings used in the CLIMB manuscript. The user can specify:

1. `reduced_classes`: the matrix of candidate latent classes generated by `get_reduced_classes()`

2. `fits`: the list of pairwise fits generated by `get_pairwise_fits()`

3. `parallel`: logical specifying if the analysis should be run in parallel (defaults to FALSE)

4. `ncores`: if in parallel, how many cores to use. Defaults to 20.

5. `delta`: this is the range of thresholds to try, but it will defaults to a sequence of all possible thresholds.

**NB:** while parallelization is always available here, it is not always necessary. Speed of this portion depends on sample size, dimension, and the number of candidate latent classes (in `reduced_classes`). 

Now, we are ready to compute the prior weights.
```{r, message = FALSE, echo = 3:11}
library(CLIMB)

# Read in the candidate latent classes produced in the last step
reduced_classes <- read.table("output/red_class.txt", sep = "\t")

# load in the pairwise fits from the first step
# (in this example case, I am simply loading the data from the package)
data("fits")

# Compute the prior weights
prior_weights <- get_prior_weights(reduced_classes, fits, parallel = FALSE)

```

`prior_weights` is a list of vectors. Each vector corresponds to the computed prior weights for a given value of $\delta$. Here, `prior_weights[[j]]` corresponds to the prior weights when $\delta = j-1$.

### <i><b><span style="color:salmon">Here requires the human intervention</span></b></i>

We can plot how the number of latent classes included in the final model changes as we relax $\delta$.

```{r}
# this is just grabbing the sample size and dimension
n <- length(fits[[1]]$cluster)
D <- as.numeric(strsplit(tail(names(fits),1), "_")[[1]][2])

# to avoid degenerate distributions, we will only keep clusters such that the prior
# weight times the sample size is greater than the dimension.
plot(
    0:choose(D,2),
    sapply(prior_weights, function(X)
    sum(X * n > D)),
    ylab = "number of retained classes",
    xlab =  expression(delta))
```

This toy example is much cleaner than a real data set, but typically we expect to see that, as we relax $\delta$ away from 0, more classes are included in the final model. We have not identified a *uniformly best* way to select $\delta$; a decent rule of thumb has simply been to include as many classes as one can while retaining computational feasibility, and selecting the *smallest* value of $\delta$ that gives this result. In this toy example, we might as well retain all classes, and thus select the prior weights corresponding to $\delta = 1$. Let's store that in the variable `p`.

```{r}
# Select out prior weights for delta = 1
p <- prior_weights[[2]]

# Filter out classes which have too small of a prior weight
# (In this toy example, we actually retain everything,
#   but this is not typical for higher-dimensional/empirical analyses)
retained_classes <- reduced_classes[p * n > D, ]
p <- p[p * n > D,]

# save the retained classes for downstream analysis
readr::write_tsv(retained_classes, file = "output/retained_classes.txt", col_names = FALSE)
```

### Obtaining the remaining hyperparameters

Now that the human intervention is over, the rest is simple. Just use the function `get_hyperparameters()` to compute empirical estimates of the remaining prior hyperparameters.

```{r}
# load the data back in
data("sim")

# obtain the hyperparameters
hyp <- get_hyperparameters(sim$data, fits, retained_classes, p)

# view the output
str(hyp)
```
`hyp$kappa0` controls the informativity of the priors. To reduce informativity, one can make the elements of `kappa0` smaller (but still larger than $D$!). For example, you could use something like `hyp$kappa0 <- rep(10, D)`, instead of the automatic choice (proportional to `hyp$alpha`) which is returned from the `get_hyperparameters` function.

We can save these hyperparameters for the next step in the analysis:
```{r}
save(hyp, file = "output/hyperparameters.Rdata")
```

After these analyses, __*we have a model to describe our data*__, and are ready to [run the MCMC](running_mcmc.html).


## Session Information

```{r}
print(sessionInfo())
```
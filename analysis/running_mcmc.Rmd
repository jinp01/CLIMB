---
title: "Running the MCMC"
output:
  workflowr::wflow_html:
    toc: false
editor_options:
  chunk_output_type: console
---

  
### <i><b><span style="color:salmon">---This is likely the most time-consuming step of CLIMB analysis---</span></b></i>
  
The final step of CLIMB involves doing inference on the parsimonious Gaussian mixture using MCMC. MCMC is an iterative method, and thus 
the user needs to specify how many iterations to use. We recommend running a quick pilot analysis--say, for 10 iterations. This pilot 
analysis will give a good idea of how long an analysis will need to run for a given *larger* number of iterations (say, 20,000 
iterations).

```{r, echo = FALSE}
knitr::opts_chunk$set(autodep = TRUE, warning = FALSE, message = FALSE)
library(magrittr)
```

You can run an MCMC through a script running_mcmc.ipynb written in Python. The user needs to provide 4 arguments:
  
1. `dat`: the input data you've been using throughout the analysis

2. `hyp`: the hyperparameter values estimated in the previous step

3. `nstep`: number of MCMC iterations to run

4. `retained_classes`: the parsimonious list of candidate latent classes, after finally filtering out by prior weights as done in the 
previous step


Before running an MCMC in python, we prepare the data by saving the toy data and each hyperparameter into one Rdata file to be readable in Python:

```{r, eval=FALSE}
save(sim$data, file = "output/sim.Rdata")
save(hyp$Psi0, file = "output/hyp_Psi0.Rdata")
save(hyp$mu0, file = "output/hyp_mu0.Rdata")
save(hyp$alpha, file = "output/hyp_alpha.Rdata")
save(hyp$kappa0, file = "output/hyp_kappa0.Rdata")
```

Next, we run CLIMB Python scripts and import modules in Python:

```{r, eval=FALSE}
%run cgibbs.ipynb
import pyreadr
import pandas as pd
import numpy as np
```

Then, we load in our data, list of candidate latent classes, and estimated hyperparameters in Python:

```{r, eval=FALSE}
sim = pyreadr.read_r('output/sim.RData')
Psi0 = pyreadr.read_r('output/hyp_Psi0.RData')
mu0 = pyreadr.read_r('output/hyp_mu0.RData')
alpha = pyreadr.read_r('output/hyp_alpha.RData')
kappa0 = pyreadr.read_r('output/hyp_kappa0.RData')
retained_classes = pd.read_csv("output/retained_classes.txt", sep="\t", header=None)
```

Next, assign MCMC parameters and setup iterations in Python:

```{r, eval=FALSE}
Psi0 = Psi0['Psi0'].values
mu0 = mu0['mu0'].values
alpha = alpha['alpha'].values.T[0]
kappa0 = kappa0['kappa0'].values.T[0]

dat = sim['sim.dat']
dm = dat.shape[1]
n = dat.shape[0]
nm = len(alpha)
nw = 1

alph = alpha
hyp = [kappa0, mu0, Psi0]
reduced_classes = retained_classes
nstep = 1000
tune_df = np.repeat(1000., nm)
reduced_classes = retained_classes
param = []
for i in range(nw) :
    dict_list = []
    for m in range(nm) :
        dictionary = {"mu":[],"Sigma":[]}
        Sigma = np.array(np.matrix(Psi0[:,:,m]).getH())
        mu = mu0[m]
        dictionary['mu']= mu
        dictionary['Sigma']= Sigma
        dict_list.append(dictionary)
    z = np.random.choice(np.arange(1, nm+1), size=n, p=p, replace=True)
    chain_i = [dict_list, alph, z]
    param.append(chain_i)
labels = np.apply_along_axis(lambda x: ''.join(map(str, x + 1)), axis=1, arr=retained_classes)
```

Now we are ready to launch an MCMC in Python:
```{r, eval=FALSE}
chain, acpt_rate_chain, tune_df_chain = run_mcmc(dat, param, hyp, alpha, nstep, labels, tune_df, opt_rate=0.3)
```

The MCMC results from Python contain 3 objects:

1. `chain`: the estimate parameters over the course of `nstep` iterations

2. `acceptane_rate_chain`: an $M\times$`nstep` matrix of the acceptance rates for each cluster covariance. The proposals for each cluster 
are adaptively tuned such that the acceptance rates converge to about 0.3

3. `tune_df_chain`: the tuning degrees of freedom across the chain, adjusted to yield optimal acceptance rates

We further extract the chain and save the output. First, recall that `M` is the number of input classes, `D` is the dimension of the data, and let `iterations` be `nstep+1`.

```{r, eval=FALSE}
# mu_chains output
mu_chains = []
for i in range(nm):
    mu_chains_i = []
    for j in range(nstep+1):
        mu_chains_i.append(result_chain[j][0][0][i]['mu'].tolist())
    mu_chains.append(mu_chains_i)
    
mu_chains_reshaped = np.array(mu_chains).reshape(np.array(mu_chains).shape[0], -1)
np.savetxt('mu_chains_reshaped.txt', mu_chains_reshaped)
```

```{r, eval=FALSE}
# Sigma_chains output
Sigma_chains = []
for i in range(nm):
    Sigma_chains_i = []
    for j in range(nstep+1):
        Sigma_chains_i.append(result_chain[j][0][0][i]['Sigma'].tolist())
    Sigma_chains.append(Sigma_chains_i)

Sigma_chains_reshaped = np.array(Sigma_chains).reshape(np.array(Sigma_chains).shape[0], -1)
np.savetxt('Sigma_chains_reshaped.txt', Sigma_chains_reshaped)
```

```{r, eval=FALSE}
# prop_chain output
prop_chain = []
for j in range(nstep+1):
    prop_chain.append(result_chain[j][0][1])

np.savetxt('prop_chain.txt', prop_chain)
```

```{r, eval=FALSE}
# z_chain output
z_chain = []
for j in range(nstep+1):
    z_chain.append(result_chain[j][0][2])

np.savetxt('z_chain.txt', z_chain)
```

The output contains:
  
  1. `mu_chains`: a list with `M` elements, each element a matrix of dimension `iterations x D`. `mu_chains[[i]]` is the MCMC samples for 
the mean vector of cluster `i`.

2. `Sigma_chains`: a list with `M` elements, each element an array of dimension `D x D x iterations`. `Sigma_chains[[i]]` is the MCMC 
samples for the covariance matrix of cluster `i`.

3. `prop_chain`: A matrix of dimension `M x iterations`, containing the MCMC samples for the mixing proportions of each class. 

4. `z_chain`: A matrix of dimension `n x iterations`, containing the MCMC samples for the class labels of each observation. These labels 
correspond to the row indices of `retained_classes` (above).

Finally, we load in the extracted data in R and save them into a list chain after reshaping.

```{r, eval=FALSE}
# adjust mu_chains
mu_chain_py_reshaped <- read.table("mu_chains_reshaped.txt", quote="\"", comment.char="")
mu_chain_py_reshaped <- as.matrix(mu_chain_py_reshaped)
nstep = 1000
mu_chains <- list()
for (i in 1:length(mu_chain_py_reshaped[,1])){
  mu_chains[[i]] <- array(mu_chain_py_reshaped[i,], dim = c(nstep+1,length(mu_chain_py_reshaped[1,])/(nstep+1)))
}

# adjust Sigma_chains
Sigma_chains_reshaped <- read.table("Sigma_chains_reshaped.txt", quote="\"", comment.char="")
Sigma_chains_reshaped <- as.matrix(Sigma_chains_reshaped)
Sigma_chains <- list()
for (i in 1:length(Sigma_chain_py_reshaped[,1])){
  Sigma_chains[[i]] <- array(Sigma_chain_py_reshaped[i,], dim = c(3,3,1001))
}

# adjust prop_chain
prop_chain <- read.table("prop_chain.txt", quote="\"", comment.char="", header = FALSE)
prop_chain <- as.matrix(prop_chain)
colnames(prop_chain) <- NULL

# adjust z_chain
z_chain <- read.table("z_chain.txt", quote="\"", comment.char="", header = FALSE)
z_chain <- as.matrix(z_chain)
z_chain <- t(z_chain)
colnames(z_chain) <- NULL

# create a list
chain <- list()
chain$mu_chains <- mu_chains
chain$Sigma_chains <- Sigma_chains
chain$prop_chain <- prop_chain
chain$z_chain <- z_chain

# save chain
if(!file.exists("output/chain.rds")) {
  saveRDS(chain, file = "output/chain.rds")
}
```

```{r, echo=FALSE}
library(rhdf5)

mu_chain_py <- h5read("~/mu_chain_py.jld", "mu_chain_py")
mu_chain_python <- list()
for (i in 1:length(mu_chain_py[1,1,])){
  mu_chain_python[[i]] <- mu_chain_py[,,i]
}

Sigma_chain_py <- h5read("~/Sigma_chain_py.jld", "Sigma_chain_py")
Sigma_chain_python <- list()
for (i in 1:length(Sigma_chain_py[1,1,1,])){
  Sigma_chain_python[[i]] <- Sigma_chain_py[,,,i]
}

prop_chain_py <- read.csv("~/prop_chain_py.csv", header=FALSE)
prop_chain_python <- data.matrix(prop_chain_py)
colnames(prop_chain_python) <- NULL

z_chain_py <- read.csv("~/z_chain_py.csv", header=FALSE)
z_chain_python <- data.matrix(z_chain_py)
colnames(z_chain_python) <- NULL

chain <- list()
chain$mu_chains <- mu_chain_python
chain$Sigma_chains <- Sigma_chain_python
chain$prop_chain <- prop_chain_python
chain$z_chain <- z_chain_python

if(!file.exists("output/chain.rds")) {
  saveRDS(chain, file = "output/chain.rds")
}
```

The Python results will contain all the different chains from the MCMC. To extract the data for R's use, for example, you can check the MCMC trace plots. Here is the trace plot of 
the mean from the first cluster in the third dimension:
  
```{r}
plot(chain$mu_chains[[1]][,3], type = "l", xlab = "iteration", ylab = expression(mu[3]))
```

## Session Information

```{r}
print(sessionInfo())
```